# üè• AI Call Agent ‚Äì Medical Clinic Voice Support System

An AI-powered phone-call-style customer support system for medical clinics. The system simulates a real phone conversation with automatic speech recognition, voice activity detection, and intelligent voice responses.

## ‚ú® Features

- üìû **Phone Call Simulation** ‚Äì Press one button to call the clinic
- üéôÔ∏è **Voice-Only Interaction** ‚Äì No text input, forms, or buttons during the call
- üß† **Intelligent AI Agent** ‚Äì Powered by LLaMA 3.2 with OpenAI structure
- üîÑ **Full Duplex Conversation** ‚Äì Listen ‚Üí Transcribe ‚Üí Reason ‚Üí Speak ‚Üí Listen loop
- üéß **Advanced Audio Pipeline** ‚Äì VAD, STT, TTS with silence detection
- üíæ **Context-Aware** ‚Äì Remembers conversation history and confirms details
- üè• **Medical-Appropriate** ‚Äì Professional, calm, and safe responses with disclaimers

## üèóÔ∏è Tech Stack

### Backend
- **FastAPI** ‚Äì High-performance Python web framework
- **OpenAI Agent** ‚Äì Structured conversational AI
- **LLaMA 3.2** ‚Äì Large Language Model
- **WebSocket** ‚Äì Real-time streaming communication
- **pyannote** ‚Äì Voice Activity Detection (VAD)
- **Whisper** ‚Äì Speech-to-Text (OpenAI)
- **pyttsx3/gTTS** ‚Äì Text-to-Speech

### Frontend
- **React** ‚Äì JavaScript UI library
- **Web Audio API** ‚Äì Microphone & audio recording
- **TypeScript** ‚Äì Type-safe development

## üìã Project Structure

```
ai-call-agent/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clinic_agent.py     # AI Agent logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_config.py       # LLaMA 3.2 configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory.py           # Conversation context manager
‚îÇ   ‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vad.py             # Voice Activity Detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stt.py             # Speech-to-Text (Whisper)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tts.py             # Text-to-Speech
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services.json       # Available medical services
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reservations.json   # Booking database
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ .env.example            # Environment variables template
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CallInterface.tsx    # Main call UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CallButton.tsx       # Single call button
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AudioVisualizer.tsx  # Real-time audio indicator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useWebSocket.ts      # WebSocket connection
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useMicrophone.ts     # Microphone control
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx             # Main app component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.tsx           # React entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ App.css         # Global styles
‚îÇ   ‚îú‚îÄ‚îÄ package.json            # Node dependencies
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json           # TypeScript config
‚îÇ   ‚îî‚îÄ‚îÄ public/
‚îÇ       ‚îî‚îÄ‚îÄ index.html          # HTML template
‚îú‚îÄ‚îÄ docker-compose.yml          # Multi-service orchestration
‚îú‚îÄ‚îÄ Dockerfile                  # Backend container
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md                   # This file

```

## üöÄ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- Docker & Docker Compose (optional)
- OpenAI API Key
- Ollama (for LLaMA 3.2) or Groq API

### Environment Setup

1. **Clone the repository**
```bash
git clone https://github.com/lukacerovic/ai-call-agent.git
cd ai-call-agent
```

2. **Create `.env` file**
```bash
cp backend/.env.example backend/.env
```

3. **Configure `.env`**
```env
# OpenAI API
OPENAI_API_KEY=your_key_here

# LLaMA Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Or use Groq instead
GROQ_API_KEY=your_groq_key_here
GROQ_MODEL=llama-3.2-70b-versatile

# Frontend
REACT_APP_API_URL=http://localhost:8000
REACT_APP_WS_URL=ws://localhost:8000/ws
```

### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

The frontend will open at `http://localhost:3000`.

### Docker Setup (Optional)

```bash
docker-compose up --build
```

This starts:
- Backend API (http://localhost:8000)
- Frontend (http://localhost:3000)
- Ollama (optional, for local LLM)

## üìö API Endpoints

### WebSocket
- `WS /ws` ‚Äì Real-time audio streaming and responses

### REST Endpoints
- `GET /health` ‚Äì Health check
- `GET /services` ‚Äì List available services
- `POST /reservations` ‚Äì Create appointment
- `GET /reservations/{patient_id}` ‚Äì Get patient's appointments

## üé§ Voice Interaction Flow

```
User presses "Call Clinic"
    ‚Üì
Microphone activates
    ‚Üì
AI speaks greeting: "Hello, thank you for calling..."
    ‚Üì
[LOOP]
    Listen for user input
    Detect silence (1-1.5 seconds)
    Transcribe speech ‚Üí text
    AI processes context
    Generate response
    Convert to speech
    Play audio
    Listen again
[END LOOP]
    ‚Üì
User says "goodbye" or timeout
    ‚Üì
Connection closes
```

## üß† AI Agent Behavior

The agent is configured as a professional medical receptionist:

‚úÖ **Behaviors:**
- Greets users warmly and professionally
- Asks one question at a time
- Listens completely before responding
- Asks clarifying questions when needed
- Confirms details verbally (name, DOB, appointment time)
- Provides information about services
- Books appointments
- Reads back details slowly and clearly

‚ùå **Never:**
- Diagnoses medical conditions
- Provides medical advice
- Makes assumptions about symptoms
- Escalates to emergency without user consent

## üìÑ Data Files

### services.json
```json
[
  {
    "id": "consultation-001",
    "name": "Initial Consultation",
    "durationMinutes": 30,
    "price": 50,
    "description": "Meet with our healthcare provider",
    "whatIsIncluded": "Medical history review, vital signs check",
    "howItsDone": "In-person at clinic",
    "specialPreparation": null
  }
]
```

### reservations.json
```json
[
  {
    "id": "res-001",
    "serviceId": "consultation-001",
    "date": "2026-01-15",
    "time": "14:00",
    "patientName": "John Doe",
    "patientDOB": "1990-05-20"
  }
]
```

## üîê Safety & Medical Disclaimers

The system implements:
- ‚úÖ Automatic disclaimer on call start
- ‚úÖ Emergency escalation protocol
- ‚úÖ No diagnosis capabilities
- ‚úÖ Context-aware medical warnings
- ‚úÖ Conversation logging for compliance

Example disclaimer:
> "Hello, thank you for calling our clinic. I'm an AI assistant. I can help you schedule appointments and provide general information, but I cannot provide medical diagnosis or emergency care. For emergencies, please call 911 or visit your nearest emergency room."

## üõ†Ô∏è Configuration

### Audio Settings
```python
# backend/audio/vad.py
VAD_THRESHOLD = 0.5
SILENCE_DURATION = 1.5  # seconds
CHUNK_SIZE = 1024
SAMPLE_RATE = 16000
```

### LLM Settings
```python
# backend/agents/llm_config.py
TEMPERATURE = 0.7  # Professional but natural
MAX_TOKENS = 150   # Keep responses concise
MODEL = "llama-3.2-70b-versatile"  # Via Groq or Ollama
```

## üìñ Development Guide

### Adding Custom Services
Edit `backend/data/services.json`:
```json
{
  "id": "dermatology-001",
  "name": "Dermatology Consultation",
  "durationMinutes": 45,
  "price": 75,
  "description": "Specialized skin care consultation",
  "whatIsIncluded": "Full skin examination, personalized treatment plan",
  "howItsDone": "In-person or telemedicine",
  "specialPreparation": "Come with clean skin, no makeup"
}
```

### Customizing AI Behavior
Edit `backend/agents/clinic_agent.py` to modify:
- Greeting message
- Available actions
- Response tone
- Confirmation protocols

### Integrating with Real Backend
Replace `reservations.json` with:
- PostgreSQL database
- REST API calls
- SMS/Email notifications

## üêõ Troubleshooting

| Issue | Solution |
|-------|----------|
| Microphone not accessible | Check browser permissions and HTTPS (required by Web Audio API) |
| No audio from AI | Verify OpenAI/Groq API key and TTS configuration |
| VAD not detecting speech | Adjust `VAD_THRESHOLD` and `SILENCE_DURATION` |
| WebSocket connection fails | Check backend is running on correct port |
| LLaMA model not found | Install Ollama or configure Groq API |

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìÑ License

MIT License ‚Äì feel free to use this project commercially.

## üîó References

- [AI Court Project](https://github.com/lukacerovic/AI_Court) ‚Äì Inspiration for agent architecture
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [OpenAI API](https://platform.openai.com/)
- [Groq API](https://groq.com/)
- [Whisper Documentation](https://github.com/openai/whisper)
- [pyannote.audio](https://github.com/pyannote/pyannote-audio)

## üìß Support

For questions or issues, please open a GitHub issue or contact the development team.

---

**Made with ‚ù§Ô∏è for medical clinics everywhere**
