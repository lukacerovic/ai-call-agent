# ğŸ” Debug: Voice Not Being Processed

**Problem**: Greeting plays, but when you speak, nothing happens. Backend doesn't receive or process your voice.

---

## ğŸ“Š What's Happening (or Not)

**Expected Flow:**
```
âœ… You speak
âœ… Frontend captures audio
âœ… Frontend sends via WebSocket
âœ… Backend receives bytes
âœ… Backend logs: ğŸ“Š Received audio chunk: X bytes
âœ… Backend detects speech (VAD)
âœ… Backend transcribes (STT)
âœ… Backend logs: ğŸ‘¤ User: [your text]
âœ… Backend sends to AI
âœ… Backend logs: ğŸ¤ Agent: [response]
âœ… Backend sends audio
âœ… You hear response
```

**What's Actually Happening:**
```
âœ… You speak
âœ… Frontend captures audio
âœ… Frontend sends via WebSocket
âŒ Backend DOESN'T LOG: ğŸ“Š Received audio chunk
âŒ Nothing else happens
```

**Root Cause**: Backend is **NOT RECEIVING audio bytes** from frontend.

---

## ğŸ”Š Enable Debug Logging

**I've already updated `.env` to enable DEBUG logging.**

Restart backend to see detailed logs:

```bash
cd backend
# Press Ctrl+C to stop

# Restart with debug logging
uvicorn main:app --reload
```

**You should now see TONS of debug messages:**

```
2026-01-03 23:58:22,008 - main - INFO - ğŸ¥ AI Call Agent starting...
2026-01-03 23:58:22,048 - main - INFO - âœ… Clinic agent initialized
2026-01-03 23:58:22,048 - main - INFO - âœ… System ready to receive calls
INFO:     Application startup complete.
INFO:     ('127.0.0.1', 63995) - "WebSocket /ws" [accepted]
2026-01-03 23:59:04,071 - main - INFO - ğŸ“ New call connected
2026-01-03 23:59:04,072 - main - INFO - ğŸ¤ Agent: Hello, thank you for calling...
INFO:     connection open
ğŸ› DEBUG LOGS APPEAR HERE WHEN YOU SPEAK
```

---

## ğŸ† Test Step-by-Step

### Step 1: Restart Backend with Debug Logs

```bash
cd backend

# Get latest code
git pull origin main

# Stop current server (Ctrl+C)

# Restart
uvicorn main:app --reload

# Watch for: LOG_LEVEL=DEBUG messages
```

### Step 2: Check Frontend Connection

```bash
# Hard refresh browser
http://localhost:3000
Ctrl+Shift+R
```

### Step 3: Open Browser DevTools

1. **Press F12**
2. **Go to Console tab**
3. **Look for any RED ERRORS**
4. **Go to Network tab**
5. **Filter by "WS" (WebSocket)**

### Step 4: Make a Call

1. Click **â™ ï¸ Call Clinic**
2. Allow microphone
3. Hear greeting
4. **Speak a few words**
5. **Pause for 2 seconds** (silence triggers sending)

### Step 5: Watch Backend Logs

**You should see in backend terminal:**

```
ğŸ“ New call connected
ğŸ¤ Agent: Hello, thank you for calling...
ğŸ“¤ Sending greeting audio: 5234 bytes
ğŸ§ Waiting for user audio...

[You speak here for 2-3 seconds]
ğŸ“¥ Receiving from WebSocket...   â† SHOULD APPEAR
ğŸ“Š Received audio chunk: 4096 bytes  â† SHOULD APPEAR
ğŸ” Running Voice Activity Detection...  â† SHOULD APPEAR
ğŸ” VAD result: True  â† IF THIS IS FALSE, YOUR MIC IS TOO QUIET
ğŸ¤ Starting Speech-to-Text...
ğŸ“ Transcription result: 'I have problems with my heart'  â† SHOULD APPEAR
ğŸ‘¤ User: I have problems with my heart
ğŸ§  Sending to agent...
ğŸ¤ Agent: I understand you're experiencing heart issues...
ğŸ”Š Converting response to speech...
ğŸ“¤ Sending response audio: 8934 bytes
âœ… Message #1 completed
```

---

## ğŸ› What to Look For

### âœ… **SUCCESS: You Should See**

```
ğŸ“¥ Receiving from WebSocket...   âœ… CRITICAL
ğŸ“Š Received audio chunk: 4096 bytes  âœ… CRITICAL
ğŸ” VAD result: True              âœ… CRITICAL
ğŸ“ Transcription result: '...'   âœ… CRITICAL
```

If you see these 4 = **Audio is flowing correctly!**

### âŒ **FAILURE: If You DON'T See**

```
âŒ ğŸ“¥ Receiving from WebSocket...   â† FRONTEND NOT SENDING
```

This means **frontend is not sending audio to backend**.

### âŒ **FAILURE: If VAD Says False**

```
ğŸ” VAD result: False  â† VOICE TOO QUIET
```

Your microphone audio is too quiet. Try:
- Speaking LOUDER
- Moving mic closer
- Checking mic volume in Windows

### âŒ **FAILURE: If STT Returns Empty**

```
ğŸ“ Transcription result: ''  â† GOOGLE STT FAILED
```

Google Speech Recognition couldn't understand. Try:
- Speaking more clearly
- Checking internet connection
- Reducing background noise

---

## ğŸ” Debugging Checklist

### Frontend Issues

```
[ ] Browser console (F12) - any RED errors?
[ ] Network tab - WebSocket connected? (status 101)
[ ] Microphone - permission granted?
[ ] Microphone - actually working?
[ ] Audio not too quiet?
```

**Test microphone:**
1. Open http://localhost:3000
2. Open DevTools (F12)
3. Go to Console
4. Paste:
```javascript
navigator.mediaDevices.getUserMedia({audio:true})
  .then(stream => console.log("Mic works!", stream))
  .catch(err => console.error("Mic failed", err))
```
5. If you see "Mic works" = microphone is accessible

### Backend Issues

```
[ ] Backend logs show "Clinic agent initialized"?
[ ] Backend logs show debug messages when you speak?
[ ] VAD showing True or False?
[ ] STT showing transcription result?
[ ] Backend processing audio OR waiting?
```

**Check specific components:**

```bash
# Test if backend is running
curl http://localhost:8000/health

# Test if Ollama is running
curl http://localhost:11434/api/tags

# Test if TTS works
curl -X POST "http://localhost:8000/debug/tts?text=hello"
```

---

## ğŸ› Most Likely Issues

### Issue 1: Frontend Not Sending Audio (Most Common)

**Symptom**: No log messages appear when you speak

**Check**:
1. Browser DevTools â†’ Network tab â†’ WebSocket connected?
2. Browser Console â†’ Any RED errors?
3. Microphone permission granted?

**Fix**:
```bash
# Hard refresh browser
http://localhost:3000
Ctrl+Shift+R

# Check browser console for errors
F12 â†’ Console tab
```

### Issue 2: Microphone Too Quiet

**Symptom**: Logs show `ğŸ” VAD result: False`

**Fix**:
- Speak **LOUDER**
- Move mic **CLOSER**
- Check Windows volume mixer

### Issue 3: Google STT Failing

**Symptom**: Logs show `ğŸ“ Transcription result: ''`

**Fix**:
- Check internet connection
- Speak **MORE CLEARLY**
- Reduce background noise
- Use OpenAI Whisper:
  ```bash
  # Add to backend/.env
  OPENAI_API_KEY=sk-your-key-here
  ```

### Issue 4: Ollama Not Responding

**Symptom**: `ğŸ§  Sending to agent...` but no response

**Check**:
```bash
curl http://localhost:11434/api/tags

# Should return models, if not:
ollama list  # Check models
ollama serve  # Restart (if not auto-running)
```

---

## ğŸ‘‹ Browser DevTools Debugging

### Check WebSocket Connection

1. **Open DevTools**: F12
2. **Network tab**
3. **Filter**: Type "ws"
4. **Click â™ ï¸ Call Clinic**
5. **Look for**: `/ws` connection

**Status should be**:
- `101 Switching Protocols` = Connected âœ…
- `Failed` or `Pending` = Problem âŒ

### Check JavaScript Errors

1. **Open DevTools**: F12
2. **Console tab**
3. **Look for**: RED text

**Common errors**:
- "Cannot access microphone" = Permission denied
- "WebSocket closed" = Backend not running
- "Unauthorized" = CORS issue

---

## ğŸ“¤ Audio Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. You Speak (Microphone)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ WebAudio API analyzes
         â”‚ ğŸ› ISSUE: May not be capturing
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Frontend records audio         â”‚
â”‚    MediaRecorder API               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Send via WebSocket
         â”‚ ğŸ› ISSUE: May not be sending
         â”‚ Check: Network tab shows data?
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Backend receives bytes          â”‚
â”‚    ğŸ“¥ Receiving from WebSocket  â”‚
â”‚ ğŸ› ISSUE: If not logged, above failed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ VAD: Detect speech
         â”‚ ğŸ› ISSUE: VAD=False? Mic too quiet
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. STT: Transcribe to text         â”‚
â”‚    Google Speech Recognition      â”‚
â”‚ ğŸ› ISSUE: Empty result? Bad audio â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Send to Ollama AI
         â”‚ Get response
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. TTS: Convert to speech           â”‚
â”‚    pyttsx3 or gTTS                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Send audio via WebSocket
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Browser plays audio             â”‚
â”‚    You hear response ğŸ”Š           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problem likely at Step 2 or 3** (frontend capturing/sending)

---

## âœ… Action Plan

1. **Pull latest code**: `git pull origin main`
2. **Restart backend**: `uvicorn main:app --reload`
3. **Hard refresh browser**: Ctrl+Shift+R
4. **Open DevTools**: F12 â†’ Network & Console tabs
5. **Call clinic**: Click button
6. **Speak**: Say a few words
7. **Watch logs**: Look for "Received audio chunk" message
8. **Report**: What do you see in backend logs?

---

**Share backend logs from when you speak and I can diagnose exactly!** ğŸ—
